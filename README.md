# Easy Tensor Compiler :computer:
Простая реализация тензорного компилятора. Для этого написан класс `etc::Tensor` и операции над ним. Сама нейронная сеть представлена как граф изменений входного тензора.

## Сборка :wrench:

К сожалению, автор этой работы пока не настолько ас, чтобы написать workflows. Поэтому просто напишу, что должно быть установлено: CMake, C++, graphviz, python3, некоторые библиотеки для Python.

В данной работе используется система сборки _CMake_. Введены некоторые особенности для запуска программы и тестов.

Во-первых, добавлен флаг `BUILD_TESTS`, который имеет 2 значения __ON__ и __OF__. Так как при тестировании программы создаются исполняемые файлы на каждый e2e-тест и один на unit-тесты.

У тестирования есть _CONFIGURATIONS_. У unit-тестов это `unit`, а у end-to-end - `e2e`.

Пример:
```
cmake -B build -DCMAKE_BUILD_TYPE=Debug -DBUILD_TESTS=ON # debug версия с тестами
cmake --build build
cmake --build build --target test ARGS="-C unit" # unit тесты
cmake --build build --target test ARGS="-C e2e" # end-to-end тесты
```

## Tensor :card_index:

Функции, которые привычно работают с матрицами, такие как конволюция и матричное умножение, работают с матрицами H_ * W_, то есть на самом последнем-предпоследнем слое матрицы.

Остальные функции имеют довольно простое определение. Вообще была попытка сделать что-то похожее на _NumPy_ и _TensorFlow_.

## Граф нейронки :deciduous_tree:
Граф состоит из потомков `INode`. Чтобы не напрягаться, лучше сделаем граф наследников.

![Рис. 1](https://github.com/Artur99M/Images/blob/main/Easy-Tensor-Compiler.png)

Классы INode, IOperation, BinaryOperation, UnaryOperation являются абстрактными. Все остальные имеют определние метода `evaluate()`, который возвращает результат операции. INumber кидает исключение. Для того, чтобы узнать значение используется метод `val()`.

## Нейронная сеть :bulb:

Вот мы и дошли до того, для чего собрались. Нейронная сеть имеет довльно простой интерфейс. Думаю, можно даже всё описать:
```C++
class NeuralNetwork {
    std::shared_ptr<INode> infer_ = nullptr;
public:
    const std::shared_ptr<IOperation>& addOp     (const std::shared_ptr<IOperation>& op)      ;
    const Tensor&                      infer     ()                                           ;
    std::string                        dump_graph()                                      const;
    const std::shared_ptr<INode>&      infer_node()                                      const;
          std::shared_ptr<INode>&      infer_node()                                           ;
};
```
Несложно заметить, что у нас всего лишь один выход, но никто не запрещает сделать либое количесвто входов. `infer()` возвращает итоговый тензор, `infer_node()` возвращает ссылку на _infer\__. Обычно это нужно для того, чтобы задать новую операцию, где прошлый выход будет являться аргументом. `dump_graph()` возвращает текст для графа _graphviz_.

`addOp` - операция, которая представляет наибольший интерес. Она добавляет в нейронку новую оперцию. Если предыдущий выход оказывает аргументом добавленной операции, то выход переходит на эту операцию. __Крайне не рекомендуется добавлять операции, не используя операцию addOp__. Из-за этого выход не будет менять свой адрес.
